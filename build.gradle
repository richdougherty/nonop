// Copyright 2025 Rich Dougherty <rich@rd.nz>

plugins {
    id 'java-library'
    id 'com.gradleup.shadow' version '8.3.6' // Can't use v9+ for Java 8 build // TODO: Make build use newer Java
}

group = "nz.rd.nonop"
version = "0.1.0-SNAPSHOT"

java {
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
    toolchain {
        languageVersion = JavaLanguageVersion.of(8)
    }
}

repositories {
    mavenCentral()
    gradlePluginPortal()
}

dependencies {

    // Annotations for checks
    compileOnly 'io.github.eisop:checker-qual:3.49.3-eisop1'

    // Byte Buddy for bytecode manipulation
    implementation 'net.bytebuddy:byte-buddy:1.17.5'
    implementation 'net.bytebuddy:byte-buddy-agent:1.17.5'

    // Utils
    implementation 'org.apache.commons:commons-lang3:3.17.0'

    // Logging
    // implementation 'org.slf4j:slf4j-api:1.7.36'
    // runtimeOnly 'org.slf4j:slf4j-simple:1.7.36'

    // Testing
    testImplementation(platform('org.junit:junit-bom:5.13.0'))
    testImplementation('org.junit.jupiter:junit-jupiter')
    testRuntimeOnly('org.junit.platform:junit-platform-launcher')
    // testImplementation 'org.mockito:mockito-core:5.18.0'
    // testImplementation 'org.mockito:mockito-junit-jupiter:5.18.0'
    testImplementation 'org.hamcrest:hamcrest:3.0'
    // Testing - utils
    testImplementation 'com.google.guava:guava:33.4.8-jre'

    // Annotations for tests
    testCompileOnly 'io.github.eisop:checker-qual:3.49.3-eisop1'

    // For JMH later
    // testImplementation 'org.openjdk.jmh:jmh-core:1.37'
    // testAnnotationProcessor 'org.openjdk.jmh:jmh-generator-annprocess:1.37'
}

jar {
    archiveBaseName = project.name
}

tasks.test {
    useJUnitPlatform()
    testLogging {
        events "passed", "skipped", "failed"
    }
}

tasks.named('shadowJar', com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar) {
    archiveBaseName = project.name
    // We add a classifier to distinguish the fat JAR from the regular one.
    archiveClassifier = 'agent'
    // Ensure all dependencies are included.
    configurations = [project.configurations.runtimeClasspath]

    // This is the core of the change: relocate dependency packages.
    // This prevents conflicts with the target application.
    relocate 'net.bytebuddy', 'nz.rd.nonop.deps.bytebuddy'
    relocate 'org.apache.commons.lang3', 'nz.rd.nonop.deps.apache.commons.lang3'

    // TODO: Enable JAR minimization once building with newer Java
    // minimize() // Requires jdependency which is not compat with Java 8

    // The Shadow plugin will automatically merge service files, but it's good practice
    // to call this explicitly.
//    mergeServiceFiles()

    // Exclude signature files and problematic module descriptors
    // This replaces your manual excludes in the old 'jar' task.
//    exclude "META-INF/*.SF"
//    exclude "META-INF/*.DSA"
//    exclude "META-INF/*.RSA"
//    exclude "module-info.class"
//    // Keep your license exclusion logic if needed
//    exclude "META-INF/LICENSE*"
//    exclude "META-INF/NOTICE*"
//    exclude "LICENSE*"

    // Copy the manifest attributes from your old 'jar' task.
    // This is critical for the JVM to recognize it as an agent.
    manifest {
        attributes(
                'Implementation-Title': project.name,
                'Implementation-Version': project.version,
                'Premain-Class': 'nz.rd.nonop.NonopAgent',
                // 'Agent-Class': 'nz.rd.nonop.NonOpAgent',
                'Can-Retransform-Classes': 'true',
                'Can-Redefine-Classes': 'false'
        )
    }
}

tasks.named('build') {
    dependsOn tasks.named('shadowJar')
}

// Directory to store benchmark results. Will be created by the task that runs the benchmarks.
def benchmarkResultsDir = file("${layout.buildDirectory.get().asFile}/benchmark-results")

// Define benchmark applications: [name: String, mainClass: String, appArgs: List<String>]
// 'name' is used for task naming, should be unique and simple (e.g., lowercase_with_underscores)
def benchmarkApps = [
        [name: 'methodCalls', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['20']],
//        [name: 'methodCalls2000', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['2000']],
//        [name: 'method_calls_100', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['100']],
         [name: 'sampleApp', mainClass: 'nz.rd.nonoptest.integration.SampleApp', appArgs: []]
         // Add more applications here
        ]

// Define JVM argument configurations: [name: String, jvmArgsProvider: Closure returning List<String>]
// Using a closure for jvmArgsProvider allows lazy evaluation of the agent JAR path.
def jvmArgConfigs = [
        [name: 'noAgent', jvmArgsProvider: { appConfig, jvmConfig -> [] }],
        [name: 'withAgent', jvmArgsProvider: { appConfig, jvmConfig -> [
                "-javaagent:${tasks.named('shadowJar').flatMap { it.archiveFile }.get().asFile.absolutePath}",
                //"-Dnonop.scan=nz.rd.nonoptest",
                "-Dnonop.out=${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.usage.log"
        ] }]]

// --- Dynamically Create Benchmark Tasks ---

benchmarkApps.each { appConfig ->
    jvmArgConfigs.each { jvmConfig ->
        def taskName = "runBenchmark_${appConfig.name}_${jvmConfig.name}"
        tasks.register(taskName, JavaExec) {
            group = "Benchmarking"
            description = "Runs benchmark '${appConfig.name}' with '${jvmConfig.name}' JVM config."

            mainClass = appConfig.mainClass
            // Assuming benchmark apps are in test sources or depend on test configurations
            classpath = sourceSets.test.runtimeClasspath

            // Application-specific arguments
            args = appConfig.appArgs

            // JVM arguments from the configuration
            // The closure ensures the agent path is resolved at execution time
            jvmArgumentProviders.add(new CommandLineArgumentProvider() {
                @Override
                Iterable<String> asArguments() {
                    return jvmConfig.jvmArgsProvider(appConfig, jvmConfig) // Call the closure with parameters
                }
            })

            // All benchmark tasks depend on the agent JAR being built
            dependsOn tasks.named('shadowJar')

            // Optional: Force tasks to always run (useful for benchmarking)
            outputs.upToDateWhen { false }

            // Optional: Redirect output to a file
            doFirst {
                benchmarkResultsDir.mkdirs() // Ensure directory exists
                // TODO: Consider TeeOutputStream (https://stackoverflow.com/questions/24633608/gradle-tasks-standardoutput-to-file-and-terminal-simultaneously)
                standardOutput = new FileOutputStream("${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.stdout.log")
                errorOutput = new FileOutputStream("${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.stderr.log")
            }
        }
    }
}

tasks.register('runBenchmarks') {
    group = "Benchmarking"
    description = "Runs all defined benchmarks."
    dependsOn tasks.matching { it.name.startsWith('runBenchmark_') }
}
plugins {
    id 'java-library'
}

group = "nz.rd.nonop"
version = "0.1.0-SNAPSHOT"

java {
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
    toolchain {
        languageVersion = JavaLanguageVersion.of(8)
    }
}

repositories {
    mavenCentral()
}

dependencies {

    // Annotations for checks
    compileOnly 'io.github.eisop:checker-qual:3.49.3-eisop1'

    // Byte Buddy for bytecode manipulation
    implementation 'net.bytebuddy:byte-buddy:1.17.5'
    implementation 'net.bytebuddy:byte-buddy-agent:1.17.5'

    // Utils
    implementation 'org.apache.commons:commons-lang3:3.17.0'

    // Logging
    // implementation 'org.slf4j:slf4j-api:1.7.36'
    // runtimeOnly 'org.slf4j:slf4j-simple:1.7.36'

    // Testing
    testImplementation(platform('org.junit:junit-bom:5.13.0'))
    testImplementation('org.junit.jupiter:junit-jupiter')
    testRuntimeOnly('org.junit.platform:junit-platform-launcher')
    // testImplementation 'org.mockito:mockito-core:5.18.0'
    // testImplementation 'org.mockito:mockito-junit-jupiter:5.18.0'
    testImplementation 'org.hamcrest:hamcrest:3.0'
    // Testing - utils
    testImplementation 'com.google.guava:guava:33.4.8-jre'

    // For JMH later
    // testImplementation 'org.openjdk.jmh:jmh-core:1.37'
    // testAnnotationProcessor 'org.openjdk.jmh:jmh-generator-annprocess:1.37'
}

// Fat JAR for distributing agent
// TODO: Shadow our dependencies
jar {
    archiveBaseName = project.name
    manifest {
        attributes(
                'Implementation-Title': project.name,
                'Implementation-Version': project.version,
                'Premain-Class': 'nz.rd.nonop.NonopAgent',
                // 'Agent-Class': 'nz.rd.nonop.NonOpAgent', // TODO: consider supporting attach-on-the-fly later
                'Can-Retransform-Classes': 'true',
                'Can-Redefine-Classes': 'false' // Declare not needed explicitly
        )
    }
    from {
        configurations.runtimeClasspath.collect { it.isDirectory() ? it : zipTree(it) }
    } {
        // Exclude signature files from dependencies, which can cause issues
        // when creating a fat JAR.
        exclude "META-INF/*.SF"
        exclude "META-INF/*.DSA"
        exclude "META-INF/*.RSA"
        // Exclude due to duplicates in byte-buddy and byte-buddy-agent
        // TODO: Work out how to merge these between apps
        exclude "META-INF/versions/9/module-info.class"
        // Exclude license/notice files from dependencies to avoid bloat/conflicts
        // if you are not redistributing them in a way that requires this.
        // Review your obligations for each dependency.
        exclude "META-INF/LICENSE*"
        exclude "META-INF/NOTICE*"
        exclude "LICENSE*" // TODO: Include licenses
    }
    // Be safe; can update if this causes an issue
    duplicatesStrategy = DuplicatesStrategy.FAIL
}

tasks.test {
    useJUnitPlatform()
    testLogging {
        events "passed", "skipped", "failed"
    }
}

// Directory to store benchmark results. Will be created by the task that runs the benchmarks.
def benchmarkResultsDir = file("${layout.buildDirectory.get().asFile}/benchmark-results")

// Define benchmark applications: [name: String, mainClass: String, appArgs: List<String>]
// 'name' is used for task naming, should be unique and simple (e.g., lowercase_with_underscores)
def benchmarkApps = [
        [name: 'methodCalls', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['20']],
//        [name: 'methodCalls2000', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['2000']],
//        [name: 'method_calls_100', mainClass: 'nz.rd.nonoptest.benchmark.BenchmarkMain', appArgs: ['100']],
         [name: 'sampleApp', mainClass: 'nz.rd.nonoptest.integration.SampleApp', appArgs: []]
         // Add more applications here
        ]

// Define JVM argument configurations: [name: String, jvmArgsProvider: Closure returning List<String>]
// Using a closure for jvmArgsProvider allows lazy evaluation of the agent JAR path.
def jvmArgConfigs = [
        [name: 'noAgent', jvmArgsProvider: { appConfig, jvmConfig -> [] }],
        [name: 'withAgent', jvmArgsProvider: { appConfig, jvmConfig -> [
                "-javaagent:${tasks.named('jar').flatMap { it.archiveFile }.get().asFile.absolutePath}",
                //"-Dnonop.scan=nz.rd.nonoptest",
                "-Dnonop.out=${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.usage.log"
        ] }]]

// --- Dynamically Create Benchmark Tasks ---

benchmarkApps.each { appConfig ->
    jvmArgConfigs.each { jvmConfig ->
        def taskName = "runBenchmark_${appConfig.name}_${jvmConfig.name}"
        tasks.register(taskName, JavaExec) {
            group = "Benchmarking"
            description = "Runs benchmark '${appConfig.name}' with '${jvmConfig.name}' JVM config."

            mainClass = appConfig.mainClass
            // Assuming benchmark apps are in test sources or depend on test configurations
            classpath = sourceSets.test.runtimeClasspath

            // Application-specific arguments
            args = appConfig.appArgs

            // JVM arguments from the configuration
            // The closure ensures the agent path is resolved at execution time
            jvmArgumentProviders.add(new CommandLineArgumentProvider() {
                @Override
                Iterable<String> asArguments() {
                    return jvmConfig.jvmArgsProvider(appConfig, jvmConfig) // Call the closure with parameters
                }
            })

            // All benchmark tasks depend on the agent JAR being built
            dependsOn tasks.named('jar')

            // Optional: Force tasks to always run (useful for benchmarking)
            outputs.upToDateWhen { false }

            // Optional: Redirect output to a file
            doFirst {
                benchmarkResultsDir.mkdirs() // Ensure directory exists
                // TODO: Consider TeeOutputStream (https://stackoverflow.com/questions/24633608/gradle-tasks-standardoutput-to-file-and-terminal-simultaneously)
                standardOutput = new FileOutputStream("${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.stdout.log")
                errorOutput = new FileOutputStream("${benchmarkResultsDir}/${appConfig.name}-${jvmConfig.name}.stderr.log")
            }
        }
    }
}

tasks.register('runBenchmarks') {
    group = "Benchmarking"
    description = "Runs all defined benchmarks."
    dependsOn tasks.matching { it.name.startsWith('runBenchmark_') }
}